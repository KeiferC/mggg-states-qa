{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mining Wikipedia Election Data\n",
    "=========================\n",
    "\n",
    "This notebook mines the data in the Wikipedia pages for the following elections:\n",
    "\n",
    "- 2016 United States presidential election\n",
    "- 2016 United States Senate elections\n",
    "- 2016 United States House of Representatives elections\n",
    "- 2017 United States Senate elections (special elections)\n",
    "- 2018 United States Senate elections\n",
    "- 2018 United States House of Representatives elections\n",
    "\n",
    "Timestamp: 12:00 PM ET, 11 Aug. 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas\n",
    "# !pip3 install wikipedia\n",
    "\n",
    "# !pip3 install git+https://github.com/KeiferC/gdutils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipedia\n",
    "import os\n",
    "import re\n",
    "\n",
    "import gdutils.datamine as dm\n",
    "import gdutils.dataqa as dq\n",
    "import gdutils.extract as et\n",
    "\n",
    "from typing import Any, List, Tuple, Dict, Hashable, Optional, Union, NoReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = [\n",
    "    'Alabama', 'Alaska','Arizona', 'Arkansas', 'California', \n",
    "    'Colorado', 'Connecticut', 'Delaware',  'Florida', 'Georgia', \n",
    "    'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', \n",
    "    'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', \n",
    "    'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', \n",
    "    'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', \n",
    "    'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', \n",
    "    'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', \n",
    "    'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', \n",
    "    'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "\n",
    "state_abbreviations = [\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', \n",
    "    'CO', 'CT', 'DE', 'FL', 'GA', \n",
    "    'HI', 'ID', 'IL', 'IN', 'IA', \n",
    "    'KS', 'KY', 'LA', 'ME', 'MD', \n",
    "    'MA', 'MI', 'MN', 'MS', 'MO', \n",
    "    'MT', 'NE', 'NV', 'NH', 'NJ', \n",
    "    'NM', 'NY', 'NC', 'ND', 'OH', \n",
    "    'OK', 'OR', 'PA', 'RI', 'SC', \n",
    "    'SD', 'TN', 'TX', 'UT', 'VT', \n",
    "    'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "states = list(zip(state_names, state_abbreviations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Generate Wikipedia page titles for scraping\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_election = ('PRES', 'United States presidential election')\n",
    "\n",
    "fed_elections = [('SEN',  'United States Senate election'),\n",
    "                 ('USH',  'United States House of Representatives election')]\n",
    "\n",
    "election_years_to_check = [2016, 2017, 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = []\n",
    "\n",
    "for yr in election_years_to_check:\n",
    "    generate_key = lambda yr, ekey, st_abv: ekey + str(yr % 100) + '_' + st_abv\n",
    "    generate_title = lambda yr, etype, st: str(yr) + ' ' + etype + ' in ' + st\n",
    "    \n",
    "    if yr % 4 == 0:\n",
    "        [wiki_titles.append((generate_key(yr, pres_election[0], st_abv),\n",
    "                             generate_title(yr, pres_election[1], st)))\n",
    "         for st, st_abv in states]\n",
    "        \n",
    "    [wiki_titles.append((generate_key(yr, ekey, st_abv),\n",
    "                         generate_title(yr, etype, st)))\n",
    "     for ekey, etype in fed_elections\n",
    "     for st, st_abv in states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Gather Wikipedia URLs from page titles\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_urls = {}\n",
    "\n",
    "# for wiki_title in wiki_titles:\n",
    "#     key, title = wiki_title\n",
    "    \n",
    "#     try:\n",
    "#         url = wikipedia.page(title=title).url\n",
    "\n",
    "#         if set(title.split(' ')).issubset(\n",
    "#                 set(re.findall('[a-zA-Z0-9]+', url))):\n",
    "#             wiki_urls[key] = (title, url)\n",
    "            \n",
    "#     except Exception:\n",
    "#         continue # it's okay if page does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print retrieved page URLs\n",
    "# Necessary for manually verifying URL-to-election mapping since\n",
    "# Wikipedia API tries to find best match, not the exact match\n",
    "\n",
    "# for wiki_key in wiki_urls:\n",
    "#     title, url = wiki_urls[wiki_key]\n",
    "#     print('{:9} : {}\\n\\t{}'.format(wiki_key, title, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Gather tabular data from Wikipedia pages\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_tables = {}\n",
    "\n",
    "# for wiki_key in wiki_urls:\n",
    "#     try:\n",
    "#         wiki_tables[wiki_key] = pd.read_html(wiki_urls[wiki_key][1])\n",
    "#     except Exception as e:\n",
    "#         print(\"Unable to gather Wikipedia tabular data:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display wikipedia tabular election data\n",
    "# Necessary for finding applicable table because a page can \n",
    "# contain multiple nameless tables whose orders differ from\n",
    "# other pages\n",
    "\n",
    "def print_wiki_tables(key):\n",
    "    for wiki in wiki_tables:\n",
    "        if wiki.startswith(key):\n",
    "            print('================================================')\n",
    "            print('Wiki: {} '.format(wiki))\n",
    "            print('================================================')\n",
    "\n",
    "            for i in range(len(wiki_tables[wiki])):\n",
    "                print('TABLE {}: ############################\\n{}\\n\\n\\n'.format(\n",
    "                        i, wiki_tables[wiki][i].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('PRES16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('SEN16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('USH16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('SEN17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('USH17') # no data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('SEN18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to save screen space\n",
    "# print_wiki_tables('USH18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Collect applicable election data from tables\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has to be done manually because every Wikipedia page \n",
    "# is different and because Wikipedia doesn't have datasets\n",
    "# to download and thus all tables are scraped\n",
    "\n",
    "# wiki_dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016 United States presidential election data (``PRES16``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unless otherwise stated, all data below are at the state-level\n",
    "\n",
    "# wiki_dfs['PRES16_AL'] = wiki_tables['PRES16_AL'][5]  \n",
    "# wiki_dfs['PRES16_AK'] = wiki_tables['PRES16_AK'][17]\n",
    "# wiki_dfs['PRES16_AZ'] = wiki_tables['PRES16_AZ'][19] \n",
    "# wiki_dfs['PRES16_AR'] = wiki_tables['PRES16_AR'][7]  \n",
    "# wiki_dfs['PRES16_CA'] = wiki_tables['PRES16_CA'][29] \n",
    "# wiki_dfs['PRES16_CO'] = wiki_tables['PRES16_CO'][20] \n",
    "# wiki_dfs['PRES16_CT'] = wiki_tables['PRES16_CT'][15] \n",
    "# wiki_dfs['PRES16_DE'] = wiki_tables['PRES16_DE'][12] \n",
    "# wiki_dfs['PRES16_FL'] = wiki_tables['PRES16_FL'][13] \n",
    "# wiki_dfs['PRES16_GA'] = wiki_tables['PRES16_GA'][12] \n",
    "# wiki_dfs['PRES16_HI'] = wiki_tables['PRES16_HI'][11] \n",
    "# wiki_dfs['PRES16_ID'] = wiki_tables['PRES16_ID'][15] \n",
    "# wiki_dfs['PRES16_IL'] = wiki_tables['PRES16_IL'][24] \n",
    "# wiki_dfs['PRES16_IN'] = wiki_tables['PRES16_IN'][14] # county-level\n",
    "# wiki_dfs['PRES16_IA'] = wiki_tables['PRES16_IA'][12] \n",
    "# wiki_dfs['PRES16_KS'] = wiki_tables['PRES16_KS'][15] \n",
    "# wiki_dfs['PRES16_KY'] = wiki_tables['PRES16_KY'][12] # county-level \n",
    "# wiki_dfs['PRES16_LA'] = wiki_tables['PRES16_LA'][8] \n",
    "# wiki_dfs['PRES16_ME'] = wiki_tables['PRES16_ME'][18] \n",
    "# wiki_dfs['PRES16_MD'] = wiki_tables['PRES16_MD'][14] \n",
    "# wiki_dfs['PRES16_MA'] = wiki_tables['PRES16_MA'][15] \n",
    "# wiki_dfs['PRES16_MI'] = wiki_tables['PRES16_MI'][16] \n",
    "# wiki_dfs['PRES16_MN'] = wiki_tables['PRES16_MN'][17] \n",
    "# wiki_dfs['PRES16_MS'] = wiki_tables['PRES16_MS'][15] \n",
    "# wiki_dfs['PRES16_MO'] = wiki_tables['PRES16_MO'][15] \n",
    "# wiki_dfs['PRES16_MT'] = wiki_tables['PRES16_MT'][10] # county-level\n",
    "# wiki_dfs['PRES16_NE'] = wiki_tables['PRES16_NE'][25] \n",
    "# wiki_dfs['PRES16_NV'] = wiki_tables['PRES16_NV'][16] \n",
    "# wiki_dfs['PRES16_NH'] = wiki_tables['PRES16_NH'][19] \n",
    "# wiki_dfs['PRES16_NJ'] = wiki_tables['PRES16_NJ'][13] \n",
    "# wiki_dfs['PRES16_NM'] = wiki_tables['PRES16_NM'][12] \n",
    "# wiki_dfs['PRES16_NY'] = wiki_tables['PRES16_NY'][26] \n",
    "# wiki_dfs['PRES16_NC'] = wiki_tables['PRES16_NC'][17] \n",
    "# wiki_dfs['PRES16_ND'] = wiki_tables['PRES16_ND'][11] \n",
    "# wiki_dfs['PRES16_OH'] = wiki_tables['PRES16_OH'][22] \n",
    "# wiki_dfs['PRES16_OK'] = wiki_tables['PRES16_OK'][18] \n",
    "# wiki_dfs['PRES16_OR'] = wiki_tables['PRES16_OR'][20] \n",
    "# wiki_dfs['PRES16_PA'] = wiki_tables['PRES16_PA'][17] \n",
    "# wiki_dfs['PRES16_RI'] = wiki_tables['PRES16_RI'][11] \n",
    "# wiki_dfs['PRES16_SC'] = wiki_tables['PRES16_SC'][14] \n",
    "# wiki_dfs['PRES16_SD'] = wiki_tables['PRES16_SD'][10] \n",
    "# wiki_dfs['PRES16_TN'] = wiki_tables['PRES16_TN'][11] \n",
    "# wiki_dfs['PRES16_TX'] = wiki_tables['PRES16_TX'][28] \n",
    "# wiki_dfs['PRES16_UT'] = wiki_tables['PRES16_UT'][12] \n",
    "# wiki_dfs['PRES16_VT'] = wiki_tables['PRES16_VT'][14] \n",
    "# wiki_dfs['PRES16_VA'] = wiki_tables['PRES16_VA'][19] \n",
    "# wiki_dfs['PRES16_WA'] = wiki_tables['PRES16_WA'][12] \n",
    "# wiki_dfs['PRES16_WV'] = wiki_tables['PRES16_WV'][9] \n",
    "# wiki_dfs['PRES16_WI'] = wiki_tables['PRES16_WI'][14] \n",
    "# wiki_dfs['PRES16_WY'] = wiki_tables['PRES16_WY'][11] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016 United States Senate election data (``SEN16``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All election data below are at the State-level\n",
    "\n",
    "# wiki_dfs['SEN16_AL'] = wiki_tables['SEN16_AL'][19] \n",
    "# wiki_dfs['SEN16_AK'] = wiki_tables['SEN16_AK'][20] \n",
    "# wiki_dfs['SEN16_AZ'] = wiki_tables['SEN16_AZ'][45]\n",
    "# wiki_dfs['SEN16_AR'] = wiki_tables['SEN16_AR'][16]\n",
    "# wiki_dfs['SEN16_CA'] = wiki_tables['SEN16_CA'][53]\n",
    "# wiki_dfs['SEN16_CO'] = wiki_tables['SEN16_CO'][25]\n",
    "# wiki_dfs['SEN16_CT'] = wiki_tables['SEN16_CT'][20]\n",
    "# wiki_dfs['SEN16_FL'] = wiki_tables['SEN16_FL'][64]\n",
    "# wiki_dfs['SEN16_GA'] = wiki_tables['SEN16_GA'][16]\n",
    "# wiki_dfs['SEN16_HI'] = wiki_tables['SEN16_HI'][18]\n",
    "# wiki_dfs['SEN16_ID'] = wiki_tables['SEN16_ID'][15]\n",
    "# wiki_dfs['SEN16_IL'] = wiki_tables['SEN16_IL'][29]\n",
    "# wiki_dfs['SEN16_IN'] = wiki_tables['SEN16_IN'][25]\n",
    "# wiki_dfs['SEN16_IA'] = wiki_tables['SEN16_IA'][20]\n",
    "# wiki_dfs['SEN16_KS'] = wiki_tables['SEN16_KS'][17]\n",
    "# wiki_dfs['SEN16_KY'] = wiki_tables['SEN16_KY'][22]\n",
    "# wiki_dfs['SEN16_LA'] = wiki_tables['SEN16_LA'][24]\n",
    "# wiki_dfs['SEN16_MD'] = wiki_tables['SEN16_MD'][29]\n",
    "# wiki_dfs['SEN16_MO'] = wiki_tables['SEN16_MO'][24]\n",
    "# wiki_dfs['SEN16_NV'] = wiki_tables['SEN16_NV'][32]\n",
    "# wiki_dfs['SEN16_NH'] = wiki_tables['SEN16_NH'][23]\n",
    "# wiki_dfs['SEN16_NY'] = wiki_tables['SEN16_NY'][15]\n",
    "# wiki_dfs['SEN16_NC'] = wiki_tables['SEN16_NC'][42]\n",
    "# wiki_dfs['SEN16_ND'] = wiki_tables['SEN16_ND'][14]\n",
    "# wiki_dfs['SEN16_OH'] = wiki_tables['SEN16_OH'][29]\n",
    "# wiki_dfs['SEN16_OK'] = wiki_tables['SEN16_OK'][12]\n",
    "# wiki_dfs['SEN16_OR'] = wiki_tables['SEN16_OR'][14]\n",
    "# wiki_dfs['SEN16_PA'] = wiki_tables['SEN16_PA'][38]\n",
    "# wiki_dfs['SEN16_SC'] = wiki_tables['SEN16_SC'][16]\n",
    "# wiki_dfs['SEN16_SD'] = wiki_tables['SEN16_SD'][9]\n",
    "# wiki_dfs['SEN16_UT'] = wiki_tables['SEN16_UT'][19]\n",
    "# wiki_dfs['SEN16_VT'] = wiki_tables['SEN16_VT'][12]\n",
    "# wiki_dfs['SEN16_WA'] = wiki_tables['SEN16_WA'][15]\n",
    "# wiki_dfs['SEN16_WI'] = wiki_tables['SEN16_WI'][21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2016 United States House of Representative election data (``USH16``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All election data below are at the State-level\n",
    "\n",
    "# wiki_dfs['USH16_AK'] = wiki_tables['USH16_AK'][15]\n",
    "# wiki_dfs['USH16_DE'] = wiki_tables['USH16_DE'][17]\n",
    "# wiki_dfs['USH16_MT'] = wiki_tables['USH16_MT'][10]\n",
    "# wiki_dfs['USH16_ND'] = wiki_tables['USH16_ND'][11]\n",
    "# wiki_dfs['USH16_SD'] = wiki_tables['USH16_SD'][8]\n",
    "# wiki_dfs['USH16_VT'] = wiki_tables['USH16_VT'][10]\n",
    "# wiki_dfs['USH16_WY'] = wiki_tables['USH16_WY'][21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017 United States Senate election data (``SEN17``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All election data below are at the State-level\n",
    "\n",
    "# wiki_dfs['SEN17_AL'] = wiki_tables['SEN17_AL'][48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2017 United States House of Representative election data (``USH17``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No such data exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2018 United States Senate election data (``SEN18``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All election data below are at the State-level\n",
    "\n",
    "# wiki_dfs['SEN18_AZ'] = wiki_tables['SEN18_AZ'][40]\n",
    "# wiki_dfs['SEN18_CA'] = wiki_tables['SEN18_CA'][54]\n",
    "# wiki_dfs['SEN18_CT'] = wiki_tables['SEN18_CT'][17] \n",
    "# wiki_dfs['SEN18_DE'] = wiki_tables['SEN18_DE'][29]\n",
    "# wiki_dfs['SEN18_FL'] = wiki_tables['SEN18_FL'][29]\n",
    "# wiki_dfs['SEN18_HI'] = wiki_tables['SEN18_HI'][14]\n",
    "# wiki_dfs['SEN18_IN'] = wiki_tables['SEN18_IN'][29]\n",
    "# wiki_dfs['SEN18_ME'] = wiki_tables['SEN18_ME'][20]\n",
    "# wiki_dfs['SEN18_MD'] = wiki_tables['SEN18_MD'][25]\n",
    "# wiki_dfs['SEN18_MA'] = wiki_tables['SEN18_MA'][29]\n",
    "# wiki_dfs['SEN18_MI'] = wiki_tables['SEN18_MI'][30]\n",
    "# wiki_dfs['SEN18_MN'] = wiki_tables['SEN18_MN'][20]\n",
    "# wiki_dfs['SEN18_MS'] = wiki_tables['SEN18_MS'][23]\n",
    "# wiki_dfs['SEN18_MO'] = wiki_tables['SEN18_MO'][35]\n",
    "# wiki_dfs['SEN18_MT'] = wiki_tables['SEN18_MT'][22]\n",
    "# wiki_dfs['SEN18_NE'] = wiki_tables['SEN18_NE'][19]\n",
    "# wiki_dfs['SEN18_NV'] = wiki_tables['SEN18_NV'][28]\n",
    "# wiki_dfs['SEN18_NJ'] = wiki_tables['SEN18_NJ'][22]\n",
    "# wiki_dfs['SEN18_NM'] = wiki_tables['SEN18_NM'][21]\n",
    "# wiki_dfs['SEN18_NY'] = wiki_tables['SEN18_NY'][16]\n",
    "# wiki_dfs['SEN18_ND'] = wiki_tables['SEN18_ND'][23]\n",
    "# wiki_dfs['SEN18_OH'] = wiki_tables['SEN18_OH'][32]\n",
    "# wiki_dfs['SEN18_PA'] = wiki_tables['SEN18_PA'][28]\n",
    "# wiki_dfs['SEN18_RI'] = wiki_tables['SEN18_RI'][17]\n",
    "# wiki_dfs['SEN18_TN'] = wiki_tables['SEN18_TN'][29]\n",
    "# wiki_dfs['SEN18_TX'] = wiki_tables['SEN18_TX'][37]\n",
    "# wiki_dfs['SEN18_UT'] = wiki_tables['SEN18_UT'][31]\n",
    "# wiki_dfs['SEN18_VT'] = wiki_tables['SEN18_VT'][13]\n",
    "# wiki_dfs['SEN18_VA'] = wiki_tables['SEN18_VA'][32]\n",
    "# wiki_dfs['SEN18_WA'] = wiki_tables['SEN18_WA'][12]\n",
    "# wiki_dfs['SEN18_WV'] = wiki_tables['SEN18_WV'][31]\n",
    "# wiki_dfs['SEN18_WI'] = wiki_tables['SEN18_WI'][27]\n",
    "# wiki_dfs['SEN18_WY'] = wiki_tables['SEN18_WY'][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2018 United States House of Representative election data (``USH18``)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All election data below are at the State-level\n",
    "\n",
    "# wiki_dfs['USH18_AK'] = wiki_tables['USH18_AK'][14]\n",
    "# wiki_dfs['USH18_DE'] = wiki_tables['USH18_DE'][19]\n",
    "# wiki_dfs['USH18_MT'] = wiki_tables['USH18_MT'][13]\n",
    "# wiki_dfs['USH18_ND'] = wiki_tables['USH18_ND'][15]\n",
    "# wiki_dfs['USH18_SD'] = wiki_tables['USH18_SD'][11]\n",
    "# wiki_dfs['USH18_VT'] = wiki_tables['USH18_VT'][12]\n",
    "# wiki_dfs['USH18_WY'] = wiki_tables['USH18_WY'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Save raw scraped tables locally\n",
    "----------------------------------------------\n",
    "\n",
    "For future auditing and granular data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for election in wiki_dfs:\n",
    "#     outpath = os.path.join('wiki', 'raw', election + '.csv')\n",
    "#     et.ExtractTable(wiki_dfs[election], \n",
    "#                     outfile=outpath).extract_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Wrangle Wikipedia data\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_key_from_candidate = {\n",
    "    'CLINTON' : 'D',\n",
    "    'HILLARY' : 'D',\n",
    "    'RODHAM'  : 'D',\n",
    "\n",
    "    'JOHNSON' : 'L',\n",
    "    'GARY'    : 'L',\n",
    "    \n",
    "    'STEIN'   : 'G',\n",
    "    'JILL'    : 'G',\n",
    "    'Ellen'   : 'G',\n",
    "    \n",
    "    'TRUMP'   : 'R',\n",
    "    'DONALD'  : 'R',\n",
    "    'JOHN'    : 'R'\n",
    "}\n",
    "\n",
    "party_key_from_party = {\n",
    "    'DEMOCRATIC'    : 'D',\n",
    "    'DEMOCRAT'      : 'D',\n",
    "    'DEMOCRATIC-NP' : 'D',\n",
    "    'GREEN'         : 'G',\n",
    "    'LIBERTARIAN'   : 'L',\n",
    "    'REPUBLICAN'    : 'R'\n",
    "}\n",
    "\n",
    "candidate_keys = list(party_key_from_candidate.keys())\n",
    "party_keys = list(party_key_from_party.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_files = dm.list_files_of_type('.csv', os.path.join('wiki', 'raw'))\n",
    "\n",
    "wiki_dfs = {}\n",
    "for file in wiki_files:\n",
    "    wiki_dfs[os.path.basename(file)[:-4]] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns list of columns in standard upper casing\n",
    "def upper_cols(df: pd.DataFrame) -> List[str]:\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            cols.append(col.upper().strip())\n",
    "        except:\n",
    "            cols.append(str(col))\n",
    "            \n",
    "    return cols\n",
    "    \n",
    "# change rows to standard upper casing\n",
    "def upper_rows():\n",
    "    for election in wiki_dfs:\n",
    "        df = wiki_dfs[election]\n",
    "\n",
    "        for name in df.columns:\n",
    "            try:\n",
    "                df[name] = df[name].str.upper()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        wiki_dfs[election] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for election in wiki_dfs:\n",
    "    wiki_dfs[election].columns = upper_cols(wiki_dfs[election])\n",
    "\n",
    "upper_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-standard data\n",
    "\n",
    "def col_has_percent(item) -> bool:\n",
    "    try:\n",
    "        return '%' in item\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def col_is_empty(item) -> bool:\n",
    "    return item is None or item is np.nan\n",
    "    \n",
    "\n",
    "def col_has_change(item) -> bool:\n",
    "    try:\n",
    "        return ('HOLD' in item or \n",
    "                'GAIN' in item or\n",
    "                'WIN'  in item or\n",
    "                'LOSE' in item)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def drop_cols(dropping_df: pd.DataFrame, cols: List[str], \n",
    "              f, threshold: Optional[float] = 0.5) -> pd.DataFrame:\n",
    "    if not cols:\n",
    "        return dropping_df\n",
    "\n",
    "    df = dropping_df.copy()\n",
    "    filtered = list(df[cols[0]].apply(lambda x: f(x)))\n",
    "    \n",
    "    if filtered.count(True) > threshold * len(filtered):\n",
    "        df = df.drop(columns=cols[0])\n",
    "    \n",
    "    cols.pop(0)\n",
    "    return drop_cols(df, cols, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp storage of partially processed raw\n",
    "\n",
    "# for election in wiki_dfs:\n",
    "#     outpath = os.path.join('wiki', 'temp', election + '.csv')\n",
    "#     et.ExtractTable(wiki_dfs[election], \n",
    "#                     outfile=outpath).extract_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_tuple(key: str) -> Tuple[str, str]:\n",
    "    key_components = key.split('_')\n",
    "    return (key_components[0], key_components[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_tuple(state_key: str) -> Tuple[str, str]:\n",
    "    state_tup = [tup for tup in states if tup[1] == state_key]\n",
    "    state_name, state_abv = state_tup[0]\n",
    "    return (state_name.upper(), state_abv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_standardized_df(state_name: str) -> pd.DataFrame:\n",
    "    standardized_cols = ['STATE', \n",
    "                         'PRES16D', 'PRES16G', 'PRES16L', 'PRES16R',\n",
    "                         'SEN16D',  'SEN16G',  'SEN16L',  'SEN16R',\n",
    "                         'USH16D',  'USH16G',  'USH16L',  'USH16R',\n",
    "                         'SEN17D',  'SEN17G',  'SEN17L',  'SEN17R',\n",
    "                         'USH17D',  'USH17G',  'USH17L',  'USH17R',\n",
    "                         'SEN18D',  'SEN18G',  'SEN18L',  'SEN18R',\n",
    "                         'USH18D',  'USH18G',  'USH18L',  'USH18R']\n",
    "    \n",
    "    standardized_data = [[state_name,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan,\n",
    "                         np.nan, np.nan, np.nan, np.nan]]\n",
    "    \n",
    "    df = pd.DataFrame(columns=standardized_cols, data=standardized_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_df(standardized, state_name) -> pd.DataFrame:\n",
    "    try:\n",
    "        return standardized[state_name]\n",
    "    except:\n",
    "        standardized[state_name] = generate_empty_standardized_df(state_name)\n",
    "        return standardized[state_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unkeyed_cols(df: pd.DataFrame, keyed: List[str]\n",
    "        ) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if col not in keyed:\n",
    "            return drop_unkeyed_cols(df.drop(columns=[col]), keyed)\n",
    "    return df\n",
    "\n",
    "\n",
    "# renames columns with names consistent with key\n",
    "def rename_raw_cols(df, election_key) -> pd.DataFrame:\n",
    "    new_cols = {}\n",
    "    \n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    for name in df.columns:\n",
    "        alpha_cols = re.findall('[a-zA-Z0-9]+', name)\n",
    "\n",
    "        for col in alpha_cols:\n",
    "            if col in candidate_keys or col in party_keys:\n",
    "                new_cols[name] = col\n",
    "                break\n",
    "\n",
    "    new_df = df.rename(columns=new_cols)\n",
    "    keyed_cols = [new_cols[col] for col in new_cols]\n",
    "    \n",
    "    new_df = drop_unkeyed_cols(new_df, keyed_cols)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_row_as_columns(df) -> pd.DataFrame:\n",
    "    df.columns = df.iloc[0].tolist()\n",
    "    return df.drop(df.index[0])\n",
    "\n",
    "def get_state_votes(df):\n",
    "    try:\n",
    "        return df[['PARTY', 'VOTES']]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return df[['PARTY.1', 'VOTES']]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return df[['CANDIDATE', 'VOTES']]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return df[['PARTY', 'POPULAR VOTE']]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return df[['CANDIDATE', 'POPULAR VOTE']]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return get_state_votes(next_row_as_columns(df))\n",
    "    except:\n",
    "        raise RuntimeError('Unable to get state votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyify_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    col_renames = {}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            col_renames[col] = party_key_from_candidate[col]\n",
    "        except:\n",
    "            col_renames[col] = party_key_from_party[col]\n",
    "            \n",
    "    return df.rename(columns=col_renames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_county_lvl(raw_df, state_abv, election_key\n",
    "        ) -> pd.DataFrame:\n",
    "    df = raw_df.copy()\n",
    "    \n",
    "    if state_abv == 'IN':\n",
    "        df = df.drop(df.index[0])\n",
    "    \n",
    "    df = df.drop(columns=[df.columns[0]])\n",
    "    df = drop_cols(df, list(df.columns), col_is_empty)\n",
    "    df = drop_cols(df, list(df.columns), col_has_percent)\n",
    "    df = rename_raw_cols(df, election_key)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            raise RuntimeError(\"Unable to cast to number\")\n",
    "    \n",
    "    df = keyify_df(df)\n",
    "    \n",
    "    col_sums = dq.sum_column_values(df, list(df.columns))\n",
    "    cols = [c for c, _ in col_sums]\n",
    "    sums = [s for _, s in col_sums]\n",
    "    \n",
    "    return pd.DataFrame(data=[sums], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_state_lvl(raw_df, state_abv, election_key\n",
    "        ) -> pd.DataFrame:\n",
    "    df = raw_df.copy()\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    \n",
    "    df = drop_cols(df, list(df.columns), col_is_empty)\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    df = drop_cols(df, list(df.columns), col_has_percent)\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    \n",
    "    df = get_state_votes(df)\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "          \n",
    "    df = df.transpose()\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    df = next_row_as_columns(df) # remove transposed numerical index\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    \n",
    "    df = drop_cols(df, list(df.columns), col_has_change, threshold=0.0)\n",
    "    df.columns = [str(x) for x in df.columns]\n",
    "    df = rename_raw_cols(df, election_key)\n",
    "    \n",
    "    # duplicate parties (col labels) \n",
    "    # -- write-ins or candidates in same party (e.g. senate races)\n",
    "    if election_key == 'PRES16':\n",
    "        if state_abv == 'WA':\n",
    "            df = df.iloc[:, :-1]\n",
    "        elif state_abv == 'TX':\n",
    "            df = df.iloc[:, :-2]\n",
    "        elif state_abv == 'VT':\n",
    "            df = df.iloc[:, :-1]\n",
    "        elif state_abv == 'HI':\n",
    "            df = df.iloc[:, :-1]\n",
    "            \n",
    "    elif election_key == 'SEN16':\n",
    "        if state_abv == 'AZ':\n",
    "            df = df.iloc[:, :-3]\n",
    "        if state_abv == 'CA':\n",
    "            df = df.iloc[:, :-1]\n",
    "            \n",
    "    elif election_key == 'SEN18':\n",
    "        if state_abv == 'CA':\n",
    "            df = df.iloc[:, :-1]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if not isinstance(list(df[col])[0], int):\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "            except:\n",
    "                df = df.drop(columns=[col])\n",
    "    \n",
    "    df = keyify_df(df)\n",
    "    \n",
    "    col_sums = dq.sum_column_values(df, list(df.columns))\n",
    "    cols = [c for c, _ in col_sums]\n",
    "    sums = [s for _, s in col_sums]\n",
    "    \n",
    "    return pd.DataFrame(data=[sums], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_wiki_df(standardized_df, raw_df, \n",
    "                        state_name, state_abv, election_key\n",
    "        ) -> pd.DataFrame:\n",
    "    # county-level wiki election data\n",
    "    if (election_key.startswith('PRES') and \n",
    "        (state_abv == 'IN' or state_abv == 'KY' or \n",
    "         state_abv == 'MT')):\n",
    "        df = standardize_county_lvl(raw_df, state_abv, \n",
    "                                    election_key)\n",
    "        \n",
    "    # state-level wiki election data\n",
    "    else:\n",
    "        df = standardize_state_lvl(raw_df, state_abv,\n",
    "                                   election_key)\n",
    "\n",
    "    # TODO -- put data into standardized\n",
    "    \n",
    "    return standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         R        D      L\n",
      "0  1479471  1380335  87531\n",
      "         D        R\n",
      "0  3755489  1730439\n",
      "        R       D      L\n",
      "0  661984  400602  43866\n",
      "        D       R      L\n",
      "0  253876  235963  14545\n",
      "        R       D      L     G\n",
      "0  409055  189765  28331  8496\n",
      "         D        R       L      G\n",
      "0  1257708  2405942  107504  27785\n",
      "        D       R       L\n",
      "0  376998  212813  107201\n",
      "         D       R      G\n",
      "0  1659907  972557  89970\n",
      "         D       R\n",
      "0  1633371  979210\n",
      "        D       R      L\n",
      "0  354649  353632  12597\n",
      "         D        R      L      G\n",
      "0  1370710  1215318  99277  36805\n",
      "        R       D\n",
      "0  237163  132810\n",
      "         D        R\n",
      "0  2355923  2053963\n",
      "        R       D\n",
      "0  536191  347816\n",
      "        R      D     L\n",
      "0  136210  61227  5658\n",
      "        R       D\n",
      "0  760241  301860\n",
      "         R        D       L      G\n",
      "0  4617886  4504975  207043  64399\n",
      "         R        D       L      G\n",
      "0  2970733  2926441  146715  49941\n",
      "        D       R      L     G\n",
      "0  252525  180543  14746  6220\n",
      "         D       R      L\n",
      "0  1491614  697017  22943\n",
      "        R       D      L\n",
      "0  547619  369567  12981\n",
      "        R       D     L\n",
      "0  202446  120816  4896\n",
      "         R        D      G\n",
      "0  3118567  1996908  88246\n",
      "        R      D\n",
      "0  223502  66268\n",
      "        R       D      L\n",
      "0  665215  328541  27607\n",
      "        D       R      L     G\n",
      "0  235603  185127  14757  6103\n",
      "         D        R\n",
      "0  1472914  1184885\n",
      "         D        R       G      L\n",
      "0  4784218  1723920  113413  48120\n",
      "         D        R      G      L\n",
      "0  1711654  1357355  25150  21212\n",
      "        R       D      L\n",
      "0  980892  355911  43421\n",
      "        R       D      L      G\n",
      "0  800983  653669  59186  11479\n",
      "         D        R       L      G\n",
      "0  1367716  1322951  112972  36985\n",
      "         R        D       L      G\n",
      "0  1252401  1161167  106327  34345\n",
      "        R       D      L\n",
      "0  285358  205919  16554\n",
      "        R       D      L\n",
      "0  732376  379740  65760\n",
      "         D        R       L       G\n",
      "0  3012940  2184692  175988  117619\n",
      "        D      R     L\n",
      "0  306604  92653  6809\n",
      "         R       D      L\n",
      "0  1241609  757022  37482\n",
      "         D        R       L      G\n",
      "0  1742718  1221747  160879  58417\n",
      "        R       D      L\n",
      "0  489371  188794  23004\n",
      "         R       D      L     G\n",
      "0  1318255  729547  44467  9391\n",
      "         R        D       L      G\n",
      "0  2362631  2189316  130126  12105\n",
      "         R        D      L      G\n",
      "0  1594511  1071068  97359  25419\n",
      "        D       R      L\n",
      "0  539260  512058  37384\n",
      "         D       R      L      G\n",
      "0  1002106  782403  94231  50002\n",
      "         R        D       L      G\n",
      "0  4685047  3877868  283492  71558\n",
      "        D       R\n",
      "0  673896  651972\n",
      "        R      D     L\n",
      "0  156176  75466  9033\n",
      "         R        D       L\n",
      "0  1423991  1158947  149481\n",
      "         R       D      L      G\n",
      "0  1522925  870695  70397  15993\n",
      "        R      D      L     G\n",
      "0  216794  93758  21434  3780\n",
      "        R       D      L     G\n",
      "0  163387  116454  18725  5735\n",
      "        D       R      L      G\n",
      "0  897572  673215  48676  22841\n",
      "        R       D\n",
      "0  265516  104140\n",
      "        R      D     L\n",
      "0  127963  59903  6918\n",
      "         R        D       L\n",
      "0  2135806  1599726  162260\n",
      "         R        D       L\n",
      "0  1161546  1025178  101153\n",
      "        D      R      L     G\n",
      "0  178573  95369  10078  6758\n",
      "         R        D       L      G\n",
      "0  2279543  2268839  172136  51463\n",
      "        R       D      L     G\n",
      "0  495961  284494  38946  8775\n",
      "         D        R       L      G\n",
      "0  1981473  1769443  118274  27638\n",
      "        R       D      L\n",
      "0  256661  233284  14476\n",
      "        D       R\n",
      "0  276316  112035\n",
      "         D        R       L       G\n",
      "0  8753788  4483810  478500  278657\n",
      "         R        D       L      G\n",
      "0  1405284  1382536  106674  31072\n",
      "        R       D\n",
      "0  449017  188249\n",
      "        R       D      L     G\n",
      "0  684872  380494  29829  9473\n",
      "         D        R      L      G\n",
      "0  2148278  1601933  72477  37772\n",
      "        R       D      L     G\n",
      "0  700714  485131  14435  3731\n",
      "        D       R      L     G\n",
      "0  348526  345790  30694  6465\n",
      "         D       R      L      G\n",
      "0  1677928  943169  79605  35945\n",
      "         D        R       L      G\n",
      "0  1338870  1202484  144121  38437\n",
      "        D       R\n",
      "0  231477  144421\n",
      "         D        R      L      G\n",
      "0  2792437  2134848  50907  31208\n",
      "         R       D\n",
      "0  1090177  813246\n",
      "         R        D\n",
      "0  4099505  4089472\n",
      "        D\n",
      "0  264414\n",
      "        D       R     G     L\n",
      "0  217385  137127  4170  3910\n",
      "        R      D      L\n",
      "0  233980  80377  23528\n",
      "        R       D      L\n",
      "0  155088  111019  31770\n",
      "        R       D      L\n",
      "0  515231  310676  39608\n",
      "        D       R      L      G\n",
      "0  357735  335593  38105  14251\n",
      "         R       D      L      G\n",
      "0  1178638  780154  37978  14031\n",
      "         D        R       L      G\n",
      "0  1995196  1090893  138018  47661\n",
      "        D       R      L     G\n",
      "0  385234  319667  74541  9879\n",
      "         R        D       L\n",
      "0  2951702  2865012  235142\n",
      "         R        D       L\n",
      "0  4835191  4122088  196956\n",
      "        D      R\n",
      "0  188547  70705\n",
      "        R       D\n",
      "0  193568  114377\n",
      "        R\n",
      "0  149779\n",
      "        R      D      L     G\n",
      "0  174419  55973  13287  2515\n",
      "         R        D       L      G\n",
      "0  2841005  2394164  174498  46271\n",
      "         D        R      L       G\n",
      "0  4379783  2527141  57438  107935\n",
      "        R       D      L\n",
      "0  926007  549460  41794\n",
      "        R       D      L\n",
      "0  949136  420375  83481\n",
      "        D       R\n",
      "0  177709  279240\n",
      "        R       D      L      G\n",
      "0  671018  427005  55406  23506\n",
      "         D        R       L      G\n",
      "0  3090729  2146015  209596  76802\n",
      "         D        R      L\n",
      "0  1910370  1374313  61565\n",
      "         R        D       G\n",
      "0  1359267  1031245  138634\n",
      "         D\n",
      "0  6019422\n",
      "         R       D\n",
      "0  1335104  748709\n",
      "         R        D      L      G\n",
      "0  1378458  1300200  67738  30743\n",
      "         R        D       L\n",
      "0  2395376  2128165  167592\n",
      "         D        R\n",
      "0  1913979  1329338\n",
      "         R       D      L      G\n",
      "0  1155389  855373  49204  13034\n",
      "        D       R      L      G\n",
      "0  266891  128847  15954  12737\n",
      "        D       R     G     L\n",
      "0  233554  172301  8326  6436\n",
      "        D       R\n",
      "0  521994  495079\n",
      "        R       D\n",
      "0  179720  144376\n",
      "         D       R      G      L\n",
      "0  1105119  651106  48823  23941\n",
      "        D       R     L     G\n",
      "0  825579  545717  8838  6618\n",
      "        R       D      L\n",
      "0  403151  269917  25349\n",
      "         D        R      G\n",
      "0  2214478  1938818  40204\n",
      "       R\n",
      "0  74815\n",
      "         D        R\n",
      "0  1033126  1557286\n",
      "         R        D       L\n",
      "0  2089104  1877963  125306\n",
      "        R       D      L\n",
      "0  227721  117458  20845\n",
      "        D       R\n",
      "0  227353  125384\n",
      "         R        D      L\n",
      "0  4260553  4045632  65470\n",
      "        R      D      L\n",
      "0  268788  58116  10556\n",
      "        D       R     L\n",
      "0  490071  441202  9196\n",
      "        R      L      D\n",
      "0  138149  90825  36200\n",
      "         D       R      L      G\n",
      "0  1008714  552621  18190  16713\n",
      "         R       D\n",
      "0  1227483  985450\n",
      "        D       R\n",
      "0  192243  103637\n",
      "         D       R      G\n",
      "0  1566174  940437  23101\n",
      "         D        R      G\n",
      "0  1191100  1135200  57442\n",
      "         D\n",
      "0  7542753\n",
      "         R        D      L      G\n",
      "0  1254927  1112935  27316  12706\n",
      "        D       R      L\n",
      "0  290510  271113  24411\n",
      "         D        R\n",
      "0  1803364  1282804\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Format for each standardized DataFrame:\n",
    "\n",
    "STATE   | PRES16D | PRES16G | PRES16L | PRES16R | SEN16D | SEN16G | ... | USH18R\n",
    "---------------------------------------------------------------------------------\n",
    "ALABAMA | ...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "standardized_wiki_dfs = {}\n",
    "\n",
    "for wiki_key in wiki_dfs:\n",
    "    election_key, state_key = get_key_tuple(wiki_key)\n",
    "    state_name, state_abv = get_state_tuple(state_key)\n",
    "    \n",
    "    raw_df = wiki_dfs[wiki_key]\n",
    "    standardized_df = get_standardized_df(standardized_wiki_dfs, state_name)\n",
    "    \n",
    "    if (election_key.startswith('PRES') or \n",
    "        election_key.startswith('SEN') or\n",
    "        election_key.startswith('USH')):\n",
    "        standardized_wiki_dfs[state_name] = \\\n",
    "            standardize_wiki_df(standardized_df, raw_df,\n",
    "                                state_name, state_abv, \n",
    "                                election_key)\n",
    "    else:\n",
    "        print('Election not currently used:', election_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Format for concatenated standardized DataFrame:\n",
    "\n",
    "STATE   | PRES16D | PRES16G | PRES16L | PRES16R | SEN16D | SEN16G | ... | USH18R\n",
    "---------------------------------------------------------------------------------\n",
    "ALABAMA | ...\n",
    "ALASKA  | ...\n",
    "...\n",
    "WYOMING | ...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "wiki_states_df = pd.DataFrame()\n",
    "for key in standardized_wiki_dfs:\n",
    "    wiki_states_df = pd.concat([wiki_states_df, standardized_wiki_dfs[key]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Save processed Wikipedia data locally\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_df_outfile = os.path.join('wiki', 'wiki_states.csv')\n",
    "\n",
    "# wiki_et = et.ExtractTable(wiki_states_df, column='STATE', \n",
    "#                 outfile=wiki_df_outfile).extract_to_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
